{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwhitez/Lora-Trainer-XL/blob/main/Waifu_Diffusion_V3_Dataser_Maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| | GitHub | Trainer XL | Tagger WDV3 (kohya)  | Tagger WDV3 | Old Trainer XL |\n",
        "| :--- | :--- | :--- | :--- | :--- | :---|\n",
        "| üè† **Original Proyect** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | | | |\n",
        "| **Modified By WhiteZ** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/gwhitez/Lora-Trainer-XL) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/gwhitez/Lora-Trainer-XL/blob/main/Fix_Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/gwhitez/Lora-Trainer-XL/blob/main/Dataset_Maker_By_WhiteZ.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/gwhitez/Lora-Trainer-XL/blob/main/Waifu_Diffusion_V3_Dataser_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/gwhitez/Lora-Trainer-XL/blob/main/Old_Fix_Lora_Trainer_XL.ipynb) |"
      ],
      "metadata": {
        "id": "uZ7el6ngA9tM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P62A6n3M1Bqe"
      },
      "outputs": [],
      "source": [
        "# @title ## **1. Install dependencies** ‚úÖ\n",
        "import os\n",
        "import shutil\n",
        "from subprocess import getoutput\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "\n",
        "output_to_drive   = True  # param {type: \"boolean\"}\n",
        "if output_to_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "#install dependencies\n",
        "    # Custom =====================\n",
        "!pip install uv\n",
        "!uv venv tagger\n",
        "!git clone https://github.com/corkborg/wd14-tagger-standalone /content/wd14_tagger\n",
        "%cd /content/wd14_tagger\n",
        "!uv pip install -r requirements.txt -q\n",
        "    # ============================\n",
        "clear_output()\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "(print(f\"DONE ‚úÖ\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ## **2. Directory Config** üìÅ\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created.\n",
        "#@markdown You can tag multiple folders by entering their paths.\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"\"  # @param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eRm_4O6J1xLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu"
      },
      "outputs": [],
      "source": [
        "# @title ## **3. Data Cleaning üî®**\n",
        "# @markdown #### Delete Unnecessary Files\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(train_data_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "# @markdown This section will delete unnecessary files and unsupported media such as `.mp4`, `.webm`, and `.gif`. These files are not used and may cause errors when training your lora.\n",
        "\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "for item in test:\n",
        "    file_ext = os.path.splitext(item)[1]\n",
        "    if file_ext not in supported_types:\n",
        "        print(f\"Deleting file {item} from {train_data_dir}\")\n",
        "        os.remove(os.path.join(train_data_dir, item))\n",
        "\n",
        "# @markdown #### <br> Convert Transparent Images\n",
        "# @markdown This code will convert your transparent dataset with alpha channel (RGBA) to RGB and give it a white background.\n",
        "\n",
        "convert = True  # @param {type:\"boolean\"}\n",
        "random_color = False  # @param {type:\"boolean\"}\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "images = [\n",
        "    image\n",
        "    for image in os.listdir(train_data_dir)\n",
        "    if image.endswith(\".png\") or image.endswith(\".webp\")\n",
        "]\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "\n",
        "def process_image(image_name):\n",
        "    img = Image.open(f\"{train_data_dir}/{image_name}\")\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            bg.save(f'{train_data_dir}/{image_name.replace(\".webp\", \".jpg\")}', \"JPEG\")\n",
        "            os.remove(f\"{train_data_dir}/{image_name}\")\n",
        "            print(\n",
        "                f\" Converted image: {image_name} to {image_name.replace('.webp', '.jpg')}\"\n",
        "            )\n",
        "        else:\n",
        "            bg.save(f\"{train_data_dir}/{image_name}\", \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            img.save(f'{train_data_dir}/{image_name.replace(\".webp\", \".jpg\")}', \"JPEG\")\n",
        "            os.remove(f\"{train_data_dir}/{image_name}\")\n",
        "            print(\n",
        "                f\" Converted image: {image_name} to {image_name.replace('.webp', '.jpg')}\"\n",
        "            )\n",
        "        else:\n",
        "            img.save(f\"{train_data_dir}/{image_name}\", \"PNG\")\n",
        "\n",
        "\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"\\033[96mAll images have been converted\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "#@markdown ### **4. Tag your images**\n",
        "#@markdown ##### **Waifu Diffusion 1.4 Tagger V3, V2, Z3D and ML Models**\n",
        "%store -r\n",
        "from IPython.display import clear_output\n",
        "\n",
        "tag_dir = \"/content/wd14_tagger\"\n",
        "os.chdir(tag_dir)\n",
        "\n",
        "#@markdown the **WD** **v1** and **v2** models work well in general use (anime, cartoon etc.), the **z3d** models are more focused on **furry** tags and the **ml** models are trained with **danbooru tags** (much more than the WD models) are more accurate but slower, I recommend using them with a **threshold** of `0.4` to `0.6`.\n",
        "MODEL = \"wd-v1-4-swinv2-tagger.v3\" # @param [\"wd-v1-4-vit-tagger.v3\",\"wd-v1-4-convnext-tagger.v3\",\"wd-v1-4-swinv2-tagger.v3\",\"wd-vit-large-tagger-v3\",\"wd-eva02-large-tagger-v3\",\"wd-v1-4-moat-tagger.v2\",\"wd14-vit.v2\",\"wd14-convnext.v2\",\"z3d-e621-convnext-toynya\",\"z3d-e621-convnext-silveroxides\",\"mld-caformer.dec-5-97527\",\"mld-tresnetd.6-30000\"]\n",
        "#@markdown More theshold lesser tags.\n",
        "threshold = 0.3 #@param {type:\"number\", min:0, max:1, step:0.05}\n",
        "#@markdown `undesire_tag` remove caption that you don't want it from the image(s). eg: `black shirt, vtuber` separated by comma.\n",
        "undesire_caption = \"bangs, breasts, multicolored hair, two-tone hair, gradient hair, virtual youtuber, parody, style parody, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color, watermark, text, bubble text, signature, artist name\" # @param {type:\"string\"}\n",
        "extension = \".txt\" # @param [\".txt\", \".caption\"]\n",
        "recursive = False # @param {type:\"boolean\"}\n",
        "overwrite_existing_caption = False # @param {type:\"boolean\"}\n",
        "\n",
        "#missing dependencies\n",
        "print(\"installing dependencies please wait\")\n",
        "!uv pip install torch==2.5.1 torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html -q\n",
        "!uv pip install fairscale==0.4.13 timm==0.6.12 -q\n",
        "!uv pip install onnxruntime-gpu==1.18.1 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/ -q\n",
        "clear_output()\n",
        "print(\"\\033[96mtagging images please wait...\\033[0m\")\n",
        "\n",
        "config = {\n",
        "    \"dir\"         : train_data_dir,\n",
        "    \"model\"       : MODEL,\n",
        "    \"threshold\"   : threshold,\n",
        "    \"ext\"         : extension,\n",
        "    \"exclude-tag\" : undesire_caption,\n",
        "}\n",
        "\n",
        "ow = \"\"\n",
        "if overwrite_existing_caption:\n",
        "  ow = \"--overwrite\"\n",
        "\n",
        "recursive = \"\"\n",
        "if recursive:\n",
        "  recursive = \"--recursive\"\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python run.py {ow} {recursive} {args}\"\n",
        "\n",
        "os.chdir(tag_dir)\n",
        "!{final_args}\n",
        "#clear_output()\n",
        "print(\"\\033[96mDONE ‚úÖ\\033[0m\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mNFLYbvT1Kfk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ### **5. Custom Caption/Tag** üìë\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(train_data_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".txt\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training.\n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = False  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = False  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)\n",
        "print(f\"finished ‚úÖ\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a9d52WT91P91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **6. Analyze Tags üìù**\n",
        "#@markdown Perhaps you need another look at your dataset.\n",
        "#@markdown **You can see the tags of various folders like this:** `my_lora/dataset/subfolder`\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "# Define the project path\n",
        "proyect_dir = train_data_dir  #param {type:\"string\"}\n",
        "\n",
        "# Defines the path of the dataset\n",
        "dataset_folder = f\"{proyect_dir}/\"\n",
        "\n",
        "show_top_tags = 50 #@param {type:\"number\"}\n",
        "\n",
        "# Check if the route exists\n",
        "if not os.path.exists(dataset_folder):\n",
        "  print(\"The dataset path does not exist\")\n",
        "  exit()\n",
        "\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(dataset_folder) if f.lower().endswith(\".txt\")]:\n",
        "  with open(os.path.join(dataset_folder, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"Top {show_top_tags} tags:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bv57uPRjCAD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **7. üìÇ Unzip dataset**\n",
        "#@markdown It's much slower to upload individual files to your Drive, so you may want to upload a zip if you have your dataset in your computer.\n",
        "zip = \"/content/drive/MyDrive/Loras/example.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OTymMkpO_qm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### **8. üî¢ Count datasets**\n",
        "#@markdown Google Drive makes it impossible to count the files in a folder, so this will show you the file counts in all folders and subfolders.\n",
        "folder = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eo_1NV_6_yNd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}